{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import copy\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset basque_glue/bec to /Users/inigoparra/.cache/huggingface/datasets/orai-nlp___basque_glue/bec/0.0.0/c40f2648a778281a8d81d35041fee72edd29fbc52d8669f787cc744e3a500c90...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a0f710d29584b59813eaeae0ab57603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/273k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bec010ab33a2409aa2774a74abfcabcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/59.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f79ec1e04b7e4893ada1a74f9ab3a3df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/59.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7f4074d488945aba593d8e797beebd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/6078 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44fe8779c34042e798255f2e1e5b78e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1302 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5795f3ae440d42259cb856fa203902d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1302 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset basque_glue downloaded and prepared to /Users/inigoparra/.cache/huggingface/datasets/orai-nlp___basque_glue/bec/0.0.0/c40f2648a778281a8d81d35041fee72edd29fbc52d8669f787cc744e3a500c90. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "636449e34a17454ea39404c6eef5c296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets = load_dataset('orai-nlp/basqueGLUE', 'bec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8c2d6b5796c474e98ffe42f287f8d0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6078 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef91b063d1d440359621f89d6400683b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1302 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "553496c909c3405bbd68b50f0f862183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1302 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = datasets.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train', 'test', 'validation'])\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_datasets.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_meta_tasks(dataset, num_tasks, support_size, query_size):\n",
    "    tasks = []\n",
    "    for _ in range(num_tasks):\n",
    "        \"\"\"Randomly sample data for support and query set\"\"\"\n",
    "        support_set = dataset.shuffle().select(range(support_size))\n",
    "        query_set = dataset.shuffle().select(range(query_size))\n",
    "        tasks.append((support_set, query_set))\n",
    "    return tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"For demonstration use the 'pos' task from BasqueGLUE\"\"\"\n",
    "dataset_pos = tokenized_datasets['train']\n",
    "tasks = create_meta_tasks(dataset_pos, num_tasks=100, support_size=5, query_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Initialize XLM-R model for POS tagging\"\"\"\n",
    "num_labels = len(set(dataset_pos[\"label\"]))\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained('xlm-roberta-base', num_labels=num_labels)\n",
    "meta_optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def meta_train(model, meta_optimizer, tasks, epochs, inner_steps, inner_lr):\n",
    "    for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n",
    "        task_progress = tqdm(tasks, desc=\"Tasks\", leave=False)\n",
    "        for task in task_progress:\n",
    "            support_set, query_set = task\n",
    "            \n",
    "            \"\"\"Prepare data for the model\"\"\"\n",
    "            support_inputs = tokenizer(support_set[\"text\"], return_tensors=\"pt\", padding=True, truncation=True)\n",
    "            support_labels = torch.tensor(support_set[\"label\"])\n",
    "            \n",
    "            query_inputs = tokenizer(query_set[\"text\"], return_tensors=\"pt\", padding=True, truncation=True)\n",
    "            query_labels = torch.tensor(query_set[\"label\"])\n",
    "            \n",
    "            \"\"\"Inner loop\"\"\"\n",
    "            fast_model = copy.deepcopy(model)\n",
    "            fast_optimizer = torch.optim.Adam(fast_model.parameters(), lr=inner_lr)\n",
    "            \n",
    "            for _ in range(inner_steps):\n",
    "                outputs = fast_model(**support_inputs, labels=support_labels)\n",
    "                loss = outputs.loss\n",
    "                loss.backward()\n",
    "                fast_optimizer.step()\n",
    "                fast_optimizer.zero_grad()\n",
    "\n",
    "            \"\"\"Compute meta-loss\"\"\"\n",
    "            outputs = fast_model(**query_inputs, labels=query_labels)\n",
    "            meta_loss = outputs.loss\n",
    "            meta_loss.backward()\n",
    "            meta_optimizer.step()\n",
    "            meta_optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Meta train\"\"\"\n",
    "meta_train(model, meta_optimizer, tasks, epochs=3, inner_steps=3, inner_lr=0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
